# 资源部分
tokenizer_path: minimind_tokenizer
output_dir: 'D:\tmp\pretrain_test'
dataset_path: 'D:\Data\pretrain_data\rainfall_hq_2.jsonl' # 数据文件需要存在，并且是jsonl格式


# 数据集相关配置
text_field: 'text' # 数据集jsonl中哪个字段表示要训练的内容
max_seq_length: 1024  # 最大长度
train_eval_percent: 99  # 训练集在整体数据集中的占比(适用于把一个文件同时拆分为训练集+验证集的场景)


# 模型相关配置
hidden_size: 256 # 隐藏层大小，Transformer块的输入输出维度
intermediate_size: 768 # 中间层大小，Transformer块的中间层维度
num_attention_heads: 16 # 注意力头数
num_hidden_layers: 4 # Transformer块的数量
num_key_value_heads: 8 # kv的头数

# 训练相关配置
# 数据加载部分
batch_size: 1
dataloader_num_workers: 1

# 计算部分
epochs: 3  # 训练轮次
learning_rate: '2e-4'
gradient_accumulation_steps: 4
lr_scheduler_type: cosine 
    
 # 保存部分
save_total_limit: 5
save_steps: 1000
save_safetensors: False

# eval部分
eval_strategy: steps
eval_steps: 1000

# 环境部分
device: cuda  # 请自行选择，可选的有cuda、cpu、mps等，如果不知道选什么，也可以删掉这个配置项，使用默认

# 监控部分
logging_steps: 10
# swanlab上报
use_swanlab: True
swanlab_project_name: rainfall_project
swanlab_experiment_name: rainfall_experiment








